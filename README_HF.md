# ğŸ¤– AI Dev Agent - NOVA System

A memory-aware, undo-capable, proactive AI developer assistant with voice support and hybrid LLM integration.

## ğŸš€ Features

### Core Capabilities

- **ğŸ§  Conversational Brain**: Intelligent task processing with dual-model strategy
- **ğŸ¤ Voice Integration**: Multi-language voice commands (English & Hindi)
- **ğŸ’¾ Memory Management**: Persistent context and conversation history
- **â†©ï¸ Undo System**: Safe operation with rollback capabilities
- **âš¡ Speed Optimizations**: Hybrid LLM routing for optimal performance

### LLM Integration

- **ğŸ”„ Hybrid Backend**: Ollama for coding, Hugging Face for speed testing
- **ğŸ§  Multiple Models**: Support for various model sizes and configurations
- **âš¡ Intelligent Routing**: Automatic backend selection based on task type
- **ğŸ“Š Performance Monitoring**: Detailed speed and memory metrics

### Voice System

- **ğŸŒ Multi-language**: English and Hindi voice recognition
- **ğŸ¯ Command Processing**: Natural language to action mapping
- **âš¡ Real-time**: Continuous listening with low latency
- **ğŸ”Š Text-to-Speech**: Voice responses and feedback

## ğŸ—ï¸ Architecture

```
AI Dev Agent/
â”œâ”€â”€ agents/                 # Core AI components
â”‚   â”œâ”€â”€ conversational_brain.py
â”‚   â”œâ”€â”€ hybrid_llm_connector.py
â”‚   â”œâ”€â”€ huggingface_connector.py
â”‚   â””â”€â”€ llm_connector.py
â”œâ”€â”€ app/                   # Application layer
â”‚   â”œâ”€â”€ bootstrap.py
â”‚   â”œâ”€â”€ controller.py
â”‚   â””â”€â”€ router.py
â”œâ”€â”€ voice/                 # Voice processing
â”‚   â”œâ”€â”€ voice_system.py
â”‚   â”œâ”€â”€ enhanced_voice_system.py
â”‚   â””â”€â”€ commands.py
â”œâ”€â”€ executor/              # Task execution
â”‚   â”œâ”€â”€ code_editor.py
â”‚   â”œâ”€â”€ file_ops.py
â”‚   â””â”€â”€ shell_ops.py
â”œâ”€â”€ memory/                # Memory management
â”‚   â””â”€â”€ memory_manager.py
â”œâ”€â”€ undo/                  # Undo system
â”‚   â””â”€â”€ undo_manager.py
â””â”€â”€ config/                # Configuration files
    â”œâ”€â”€ settings.yaml
    â”œâ”€â”€ settings_hybrid.yaml
    â””â”€â”€ settings_huggingface.yaml
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/ai-dev-agent.git
cd ai-dev-agent

# Install dependencies
pip install -r requirements.txt

# For Hugging Face integration
pip install -r requirements_huggingface.txt
```

### Configuration

```bash
# Use hybrid configuration (recommended)
cp config/settings_hybrid.yaml config/settings.yaml

# Or use Hugging Face only
cp config/settings_huggingface.yaml config/settings.yaml
```

### Running

```bash
# Start the AI Dev Agent
python main.py

# Run speed tests
python test_hybrid_speed.py
python test_huggingface_speed.py
```

## ğŸ§  Hybrid LLM System

### Backend Selection

| Task Type            | Backend      | Use Case                                |
| -------------------- | ------------ | --------------------------------------- |
| **Coding**           | Ollama       | Code generation, debugging, refactoring |
| **Simple Q&A**       | Hugging Face | Quick responses, voice commands         |
| **Complex Analysis** | Ollama       | Detailed reasoning, problem solving     |
| **Speed Testing**    | Hugging Face | Performance comparison, optimization    |

### Model Configurations

```yaml
# Ollama (Coding Tasks)
ollama:
  model_name: "deepseek-coder-v2:lite"
  temperature: 0.3
  max_tokens: 2048

# Hugging Face (Speed Tasks)
huggingface:
  models:
    fast:
      model_name: "microsoft/DialoGPT-small"
      max_tokens: 512
    balanced:
      model_name: "microsoft/DialoGPT-medium"
      max_tokens: 1024
```

## ğŸ¤ Voice Commands

### English Commands

- "Open main.py"
- "Create new function"
- "Run tests"
- "Save all files"
- "Undo last action"

### Hindi Commands

- "file kholo"
- "function banane ke liye"
- "test run karo"
- "sab files save karo"
- "last action undo karo"

## ğŸ“Š Performance

### Speed Test Results

- **Ollama (Coding)**: ~0.5-1.0s response time
- **Hugging Face (Simple)**: ~0.2-0.3s response time
- **Voice Processing**: ~0.1-0.2s latency
- **Memory Usage**: 200MB-1.5GB depending on model

### Optimization Features

- **Prompt Caching**: 90%+ cache hit rate for repeated requests
- **Model Quantization**: 8-bit models for faster inference
- **Lazy Loading**: Models loaded on demand
- **Health Monitoring**: Automatic fallback and recovery

## ğŸ”§ Configuration

### Hybrid Configuration

```yaml
llm:
  model_type: "hybrid"
  routing:
    default_backend: "ollama"
    coding_keywords: ["code", "function", "debug", "refactor"]
    simple_keywords: ["hello", "what is", "explain briefly"]
```

### Voice Configuration

```yaml
voice:
  enabled: true
  model_size: "base.en"
  supported_languages: ["en", "hi"]
  min_confidence: 0.6
```

## ğŸ§ª Testing

### Speed Tests

```bash
# Test hybrid system
python test_hybrid_speed.py

# Test Hugging Face only
python test_huggingface_speed.py

# Test voice system
python test_voice.py
```

### Performance Monitoring

```python
from agents.hybrid_llm_connector import HybridLLMConnector

connector = HybridLLMConnector(config)
metrics = connector.get_performance_metrics()
print(f"Cache hit rate: {metrics['cache_hit_rate']:.1%}")
print(f"Average response time: {metrics['avg_response_time']:.3f}s")
```

## ğŸ“ˆ Roadmap

- [ ] **Advanced Code Analysis**: AST-based code understanding
- [ ] **Multi-modal Support**: Image and video processing
- [ ] **Collaborative Features**: Team development support
- [ ] **Plugin System**: Extensible architecture
- [ ] **Cloud Integration**: Remote model serving

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama**: For local model serving
- **Hugging Face**: For model hosting and optimization
- **Whisper**: For voice recognition
- **OpenAI**: For inspiration and best practices

---

**Made with â¤ï¸ by Shubham25180**

_Your AI Development Companion_
