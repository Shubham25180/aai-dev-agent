# NOVA AI Development Assistant - Speed Optimized Requirements
# Optimized for maximum performance with local models and fast processing

# Core dependencies
asyncio>=3.4.3
aiofiles>=23.2.1
aiohttp>=3.9.1
numpy>=1.24.0
PyYAML>=6.0.1

# Voice System Optimizations
# Whisper.cpp for fast speech-to-text
whisper-cpp>=1.0.0
# Alternative: Python Whisper (slower but more accessible)
openai-whisper>=20231117

# Voice Activity Detection
webrtcvad>=2.0.10
# Audio processing
pyaudio>=0.2.11
sounddevice>=0.4.6

# Text-to-Speech engines (fast options)
pyttsx3>=2.90
edge-tts>=6.1.9  # Windows Edge TTS (faster than pyttsx3)

# LLM Connector Optimizations
# Ollama for local model serving
ollama>=0.1.7
# GPT4All for lightweight models
gpt4all>=2.0.2
# LLaMA.cpp for maximum speed
llama-cpp-python>=0.2.20

# Alternative LLM backends
transformers>=4.36.0
torch>=2.1.0
accelerate>=0.25.0

# File Operations Optimizations
# Async file operations
aiofiles>=23.2.1
# Memory mapping for large files
mmap-io>=0.1.0

# Memory Management
# Fast JSON processing
orjson>=3.9.10
# Efficient data structures
numpy>=1.24.0
pandas>=2.1.0

# Logging and Monitoring
# Structured logging
structlog>=23.2.0
# Performance monitoring
psutil>=5.9.0

# System Integration
# Cross-platform compatibility
platform>=1.0.8
# Process management
psutil>=5.9.0

# Development and Testing
# Type checking
mypy>=1.7.0
# Code formatting
black>=23.11.0
# Linting
flake8>=6.1.0
# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0

# Optional: GPU Acceleration (if available)
# CUDA support for PyTorch
# torch>=2.1.0+cu118  # Uncomment for CUDA 11.8
# torch>=2.1.0+cu121  # Uncomment for CUDA 12.1

# Optional: Advanced Audio Processing
# For better audio quality
librosa>=0.10.1
# For real-time audio
pyaudio>=0.2.11

# Optional: Web Interface
# For web-based control
fastapi>=0.104.0
uvicorn>=0.24.0
websockets>=12.0

# Optional: Database for persistent storage
# SQLite for simple storage
sqlite3  # Built-in Python module
# Alternative: PostgreSQL for larger scale
# psycopg2-binary>=2.9.7

# Performance Monitoring
# For detailed performance analysis
py-spy>=0.3.14
# For memory profiling
memory-profiler>=0.61.0

# Security
# For secure configuration
cryptography>=41.0.0
# For environment variable management
python-dotenv>=1.0.0

# Documentation
# For API documentation
sphinx>=7.2.0
# For code documentation
docstring-parser>=0.15

# Platform-specific optimizations
# Windows-specific
pywin32>=306; sys_platform == "win32"
# Linux-specific
# No additional requirements needed
# macOS-specific
# No additional requirements needed

# Development tools
# For dependency management
pip>=23.0.0
# For virtual environments
virtualenv>=20.24.0

# Optional: Cloud integration
# For cloud-based models (if needed)
# openai>=1.3.0
# anthropic>=0.7.0

# Optional: Advanced features
# For image processing (if needed)
# pillow>=10.0.0
# For web scraping (if needed)
# requests>=2.31.0
# beautifulsoup4>=4.12.0

# Performance notes:
# - Use Whisper.cpp for fastest speech-to-text
# - Use Ollama for persistent local model serving
# - Use Edge TTS on Windows for fastest text-to-speech
# - Enable GPU acceleration where available
# - Use async operations for non-blocking performance
# - Implement caching for repeated operations
# - Use batch processing for multiple files/operations 